# Deep-learning-based-smart-glasses

# Video explanation: https://youtu.be/csdE4u53GRk

# ABSTRACT
In the world of colors, It’s sad that some people can’t see because of some kind of visual impairment. So, we decided to build novel smart glasses based on a machine learning model. These glasses can be capable of recognizing the images and produce output in audio format, so that the person with the visual impairment is able to hear and visualize what is in front of them

# HARDWARE:
- Jetson nano
- Display
- Keyboard and mouse
- Power adapter
- ethernet cable
- camera
- speaker
- Glassses

# SOFTWARE TOOLS USED
- Google text to speech service
- Google net
- Jetson interface
- UBUNTU interface

# DESIGN
![Screenshot 2022-05-08 151622](https://user-images.githubusercontent.com/81625376/167314700-fb84b82e-7ede-40b4-b147-b05b263f6625.png)

# MODEL
![Screenshot 2022-05-08 153502](https://user-images.githubusercontent.com/81625376/167315000-14236367-302c-4918-be10-120df8af73af.png)

# FUTURE WORK
- We planned to include the text recognition feature to the smart glasses which can be used to read the test from the image captured by the camera.
- We are also planning to implement the new feature in the future which allows glasses to remember faces and objects from which are not in the dataset, i.e.If smart glasses encounter a new object then the user will be able to add the name of the object to the memory of smart glasses. So that glasses are able to detect an object if we ask it again.

# ![WhatsApp Image 2022-05-07 at 11 14 36 PM](https://user-images.githubusercontent.com/81625376/167314742-3203e453-d981-4676-8a1d-24eef61047ab.jpeg)

![Screenshot 2022-05-08 153341](https://user-images.githubusercontent.com/81625376/167314790-cc23bd84-97c0-4524-adb3-990fe1965f35.png)



